* AutoEncoder(MNIST手写数字集)
** 实验目的
自编码器
** 理论基础
** 数据来源
MNIST手写数字集
** 实验步骤
** 结果分析与讨论
** 结论
>>>>>>> 5ba4ef6 (reconnect)
* CNNmatching模型提取火焰信息
** 实验目的
利用深度学习中CNN神经网络对图片进行匹配的模型，对火焰图像进行处理匹配特征点。
** 理论基础
卷积神经网络(Convolutional Neural Networks, CNN)由纽约大学的Yann　LeCun于1998年提出，CNN中层次之间的紧密联系和空间信息使得其特别适用于图像的处理和理解，并且能够自动的从图像抽取出丰富的相关特性。CNN是一种深度的监督学习下的机器学习模型，具有极强的适应性，善于挖掘数据局部特征，提取全局训练特征和分类，它的权值共享结构网络使之更类似于生物神经网络，在模式识别各个领域都取得了很好的成果。
1. 稀疏连接：在BP神经网络中，每一层的神经元节点是一个线性一维排列结构，层与层各神经元节点之间是全连接的。卷积神经网络中，层与层之间的神经元节点不再是全连接形式，利用层间局部空间相关性将相邻每一层的神经元节点只与和它相近的上层神经元节点连接，即局部连接。这样大大降低了神经网络架构的参数规模。
2. 权重共享：在卷积神经网络中，卷积层的每一个卷积滤波器重复的作用于整个感受野中，对输入图像进行卷积，卷积结果构成了输入图像的特征图，提取出图像的局部特征。每一个卷积滤波器共享相同的参数，包括相同的权重矩阵和偏置项。共享权重的好处是在对图像进行特征提取时不用考虑局部特征的位置。而且权重共享提供了一种有效的方式，使要学习的卷积神经网络模型参数数量大大降低。
3. 最大池采样：它是一种非线性降采样方法。在通过卷积获取图像特征之后是利用这些特征进行分类。可以用所有提取到的特征数据进行分类器的训练，但这通常会产生极大的计算量。所以在获取图像的卷积特征后，要通过最大池采样方法对卷积特征进行降维。将卷积特征划分为数个n*n的不相交区域，用这些区域的最大(或平均)特征来表示降维后的卷积特征。这些降维后的特征更容易进行分类。
4. Softmax回归：它是在逻辑回归的基础上扩张而来，它的目的是为了解决多分类问题。在这类问题中，训练样本的种类一般在两个以上。Softmax回归是有监督学习算法，它也可以与深度学习或无监督学习方法结合使用。

针对深度遥感影像在成像方式，时间相位和分辨率上的差异使得匹配困难的问题，提出了一种新的深度学习特征匹配方法，其特征提取的主要思想和代码均基于D2-Net。
** 数据来源
示例程序源数据（一组名为“df-sm-data”的测试数据，包括来自星载SAR和可见光传感器的图像，无人机热红外传感器以及Google Earth图像）；火电厂视频数据截取的火焰图像。
** 实验步骤
1. 用openCV将火焰视频逐帧截取成每秒25张的火焰图像。
2. 将处理后的火焰图像输入到cnn-matching模型中。
3. 通过运行以wget https://dsmn.ml/files/d2-net/d2_tf.pth -O models/d2_tf.pth命令下载现成的VGG16权重及其已调整的对应权重。
4. 利用CNN模型提取图像特征，torch下的DenseFeatureExtractionModule模型结构如下：
[[./img/cnn-matching/DenseFeatureExtractionModule.png]]
5. 利用Flann特征匹配处理所提取的图像特征，包括匹配对筛选、统计平均距离差、自适应阈值。
6. 输出最终匹配结果，并绘制匹配连线。
** 结果分析与讨论
1. 谷歌地球图像之间的匹配结果（2009年和2018年）:
[[./img/cnn-matching/reslut_1.jpeg]]
2. 无人机光学图像与红外热像的匹配结果:
[[./img/cnn-matching/reslut_2.jpeg]]
3. SAR图像（GF-3）与光学卫星（ZY-3）图像的匹配结果:
[[./img/cnn-matching/reslut_3.jpeg]]
4. 卫星图与地图的匹配结果:
[[./img/cnn-matching/reslut_4.jpeg]]
5. 火焰图像相邻前后帧的匹配结果：
[[./img/cnn-matching/result_512.png]]
[[./img/cnn-matching/result_523.png]]
[[./img/cnn-matching/result_612.png]]
[[./img/cnn-matching/result_623.png]]
6. 输入同一帧火焰图像的匹配结果：
[[./img/cnn-matching/result_5.png]]
[[./img/cnn-matching/result_6.png]]
** 结论
该算法具有较强的适应性和鲁棒性，在匹配点的数量和分布，效率和适应性方面均优于其他算法。但对于前后帧火焰图像火焰纹理的特征点抓取不够理想，输入为同一帧的火焰图像时效果明显提升。
* SIFT算法提取火焰信息(将灰度矩阵用线性插值处理)
** 实验目的
在python+openCV环境下，使用SIFT算法提取前后帧火焰图片中的相似点。
** 理论基础
SIFT的全称是Scale Invariant Feature Transform，尺度不变特征变换，由加拿大教授David G.Lowe提出。SIFT特征对旋转、尺度缩放、亮度变化等保持不变性，是一种非常稳定的局部特征。
1. SIFT算法具的特点
   1. 图像的局部特征，对旋转、尺度缩放、亮度变化保持不变，对视角变化、仿射变换、噪声也保持一定程度的稳定性。
   2. 独特性好，信息量丰富，适用于海量特征库进行快速、准确的匹配。
   3. 多量性，即使是很少几个物体也可以产生大量的SIFT特征
   4. 高速性，经优化的SIFT匹配算法甚至可以达到实时性
   5. 扩招性，可以很方便的与其他的特征向量进行联合。
2. SIFT特征检测的四个主要步骤：
   1) 尺度空间的极值检测：搜索所有尺度空间上的图像，通过高斯微分函数来识别潜在的对尺度和选择不变的兴趣点。
   2) 特征点定位：在每个候选的位置上，通过一个拟合精细模型来确定位置尺度，关键点的选取依据他们的稳定程度。
   3) 特征方向赋值：基于图像局部的梯度方向，分配给每个关键点位置一个或多个方向，后续的所有操作都是对于关键点的方向、尺度和位置进行变换，从而提供这些特征的不变性。
   4) 特种点描述：在每个特征点周围的邻域内，在选定的尺度上测量图像的局部梯度，这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变换。
** 数据来源
火电厂视频数据截取的火焰图像
** 实验步骤
1. 用openCV将火焰视频逐帧截取成每秒25张的火焰图像
2. 对火焰图像进行处理，仅使用图像中观察孔的火焰部分
3. 将火焰图像进行灰度化处理
4. 将火焰图像进行增强处理
5. 将处理后的火焰图像输入到SIFT模型中
6. 计算出SIFT的关键点和描述符。
7. 对FLANN进行初始化，使用FlannBasedMatcher 寻找最近邻近似匹配，使用KTreeIndex配置索引，使用knnMatch匹配处理，并返回匹配matches，通过掩码方式计算有用的点。
8. 通过描述符的距离进行选择需要的点，通过设置coff系数来决定匹配的有效关键点数量。
9. 估计模板和场景之间的单应性，计算第二张图相对于第一张图的畸变。
10. 在场景图像中绘制检测到的模板。
11. 绘制SIFT关键点匹配。
** 结果分析与讨论
*** 灰度化
确定灰度值的max和min并设置为上下限，然后对其他像素点的灰度值进行线性插值

处理前[[./img/gray1.png]]

处理后[[./img/test1.png]]

输入到模型后无法提取到有用信息，提示“Not enough matches are found”
*** 增强处理
1. 先用高斯滤波处理图像，再增强图像对比度，再进行灰度值变换，然后进行空间域kirsch锐化
   1) 具体流程：[[./img/chuliguocheng1.png]]
   2) 处理前：[[./img/orgin1.png]]
   3) 处理后：[[./img/enhance11.png]] 
   4) 输入到模型训练结果[[./img/enhance_SIFT1.png]]
2. 先用掩码对图片进行裁剪后转为灰度图，再用高斯滤波处理图像，接着对其增强对比度，再进行灰度值线性变换，然后进行空间域Kirsch锐化
   1) 具体处理流程：[[./img/chuliguocheng2.png]]
   2) 处理前[[./img/origin1.jpg]]
   3) 处理后[[./img/enhance1.png]]
   4) 输入到模型训练结果为[[./img/enhance_SIFT2.png]]

由实验结果可看出，模型提取到的主要为边缘轮廓的特征点，对火焰的边缘仅有非常有限的捕捉
*** 输入相同图片
为了验证模型的提取能力，输入同一张的图进行训练，观察其提取特征点的能力
1. 灰度处理的图片输入后仍然无法提取到有用信息，提示“Not enough matches are found”
2. 第一种增强处理后的相同图片输入后，训练结果为[[./img/enhance_SIFT_same1.png]]
3. 第二种增强处理后的相同图片输入后，训练结果为[[./img/enhance_SIFT_same2.png]]
** 结论
经过处理的火焰图像输入到该模型中提取到的信息无法满足课题要求，可考虑更换模型，或调整处理图像的方法。
* SIFT算法提取火焰信息(将图像进行灰度化和二值化处理)
** 实验目的
在python+openCV环境下，使用SIFT算法提取前后帧火焰图片中的相似点。
** 理论基础
SIFT的全称是Scale Invariant Feature Transform，尺度不变特征变换，由加拿大教授David G.Lowe提出。SIFT特征对旋转、尺度缩放、亮度变化等保持不变性，是一种非常稳定的局部特征。
1. SIFT算法具的特点
   1. 图像的局部特征，对旋转、尺度缩放、亮度变化保持不变，对视角变化、仿射变换、噪声也保持一定程度的稳定性。
   2. 独特性好，信息量丰富，适用于海量特征库进行快速、准确的匹配。
   3. 多量性，即使是很少几个物体也可以产生大量的SIFT特征
   4. 高速性，经优化的SIFT匹配算法甚至可以达到实时性
   5. 扩招性，可以很方便的与其他的特征向量进行联合。
2. SIFT特征检测的四个主要步骤：
   1) 尺度空间的极值检测：搜索所有尺度空间上的图像，通过高斯微分函数来识别潜在的对尺度和选择不变的兴趣点。
   2) 特征点定位：在每个候选的位置上，通过一个拟合精细模型来确定位置尺度，关键点的选取依据他们的稳定程度。
   3) 特征方向赋值：基于图像局部的梯度方向，分配给每个关键点位置一个或多个方向，后续的所有操作都是对于关键点的方向、尺度和位置进行变换，从而提供这些特征的不变性。
   4) 特种点描述：在每个特征点周围的邻域内，在选定的尺度上测量图像的局部梯度，这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变换。
** 数据来源
火电厂视频数据截取的火焰图像
** 实验步骤
1. 用openCV将火焰视频逐帧截取成每秒25张的火焰图像
2. 对火焰图像进行处理，仅使用图像中观察孔的火焰部分
3. 将火焰图像进行灰度化处理
4. 将火焰图像进行二值化处理
5. 将处理后的火焰图像输入到SIFT模型中
6. 计算出SIFT的关键点和描述符。
7. 对FLANN进行初始化，使用FlannBasedMatcher 寻找最近邻近似匹配，使用KTreeIndex配置索引，使用knnMatch匹配处理，并返回匹配matches，通过掩码方式计算有用的点。
8. 通过描述符的距离进行选择需要的点，通过设置coff系数来决定匹配的有效关键点数量。
9. 估计模板和场景之间的单应性，计算第二张图相对于第一张图的畸变。
10. 在场景图像中绘制检测到的模板。
11. 绘制SIFT关键点匹配。
** 结果分析与讨论
1. 火焰图像灰度化结果：[[./img/0339_gray.PNG]]
2. 火焰图像二值化结果：[[./img/0339_binary.PNG]]
3. 截取后的火焰图像灰度化结果：[[./img/0339_crop_gray.PNG]]
4. 截取后的火焰图像二值化结果：[[./img/0339_crop_binary.PNG]]
5. 将火焰图像进行灰度化后输入到模型中无法提取到前后帧图像数据的相似点；
6. 将火焰图像二值化后火焰信息丢失严重，无法作为有用数据输入到模型中。
** 结论
经过处理的火焰图像输入到该模型中无法提取火焰信息，可考虑更换模型，或调整二值化的方法。
* SIFT算法提取火焰信息
** 实验目的
在python环境下，使用SIFT算法提取前后帧火焰图片中的相似点。
** 理论基础
SIFT的全称是Scale Invariant Feature Transform，尺度不变特征变换，由加拿大教授David G.Lowe提出。SIFT特征对旋转、尺度缩放、亮度变化等保持不变性，是一种非常稳定的局部特征。
1. SIFT算法具的特点
   1. 图像的局部特征，对旋转、尺度缩放、亮度变化保持不变，对视角变化、仿射变换、噪声也保持一定程度的稳定性。
   2. 独特性好，信息量丰富，适用于海量特征库进行快速、准确的匹配。
   3. 多量性，即使是很少几个物体也可以产生大量的SIFT特征
   4. 高速性，经优化的SIFT匹配算法甚至可以达到实时性
   5. 扩招性，可以很方便的与其他的特征向量进行联合。
2. SIFT特征检测的四个主要步骤：
   1) 尺度空间的极值检测：搜索所有尺度空间上的图像，通过高斯微分函数来识别潜在的对尺度和选择不变的兴趣点。
   2) 特征点定位：在每个候选的位置上，通过一个拟合精细模型来确定位置尺度，关键点的选取依据他们的稳定程度。
   3) 特征方向赋值：基于图像局部的梯度方向，分配给每个关键点位置一个或多个方向，后续的所有操作都是对于关键点的方向、尺度和位置进行变换，从而提供这些特征的不变性。
   4) 特种点描述：在每个特征点周围的邻域内，在选定的尺度上测量图像的局部梯度，这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变换。
** 数据来源
火电厂视频数据截取的火焰图像
** 实验步骤
1. 用openCV将火焰视频逐帧截取成每秒25张的火焰图像
2. 对火焰图像进行处理，仅使用图像中观察孔的火焰部分
3. 将处理后的火焰图像输入到SIFT模型中
4. 计算出SIFT的关键点和描述符。
5. 对FLANN进行初始化，使用FlannBasedMatcher 寻找最近邻近似匹配，使用KTreeIndex配置索引，使用knnMatch匹配处理，并返回匹配matches，通过掩码方式计算有用的点。
6. 通过描述符的距离进行选择需要的点，通过设置coff系数来决定匹配的有效关键点数量。
7. 估计模板和场景之间的单应性，计算第二张图相对于第一张图的畸变。
8. 在场景图像中绘制检测到的模板。
9. 绘制SIFT关键点匹配。
** 结果分析与讨论
[[./img/sift_test_result_1.png]]

该模型不能有效地提取到火焰信息
** 结论
该SIFT模型不能运用到提取火焰信息中，可考虑其他SIFT模型，或openCV的其他特征提取的方法
* SIFT特征匹配的实现
** 实验目的
在python环境下，使用SIFT算法提取图片中的相似点。
** 理论基础
SIFT的全称是Scale Invariant Feature Transform，尺度不变特征变换，由加拿大教授David G.Lowe提出。SIFT特征对旋转、尺度缩放、亮度变化等保持不变性，是一种非常稳定的局部特征。
1. SIFT算法具的特点
   1. 图像的局部特征，对旋转、尺度缩放、亮度变化保持不变，对视角变化、仿射变换、噪声也保持一定程度的稳定性。
   2. 独特性好，信息量丰富，适用于海量特征库进行快速、准确的匹配。
   3. 多量性，即使是很少几个物体也可以产生大量的SIFT特征
   4. 高速性，经优化的SIFT匹配算法甚至可以达到实时性
   5. 扩招性，可以很方便的与其他的特征向量进行联合。
2. SIFT特征检测的四个主要步骤：
   1) 尺度空间的极值检测：搜索所有尺度空间上的图像，通过高斯微分函数来识别潜在的对尺度和选择不变的兴趣点。
   2) 特征点定位：在每个候选的位置上，通过一个拟合精细模型来确定位置尺度，关键点的选取依据他们的稳定程度。
   3) 特征方向赋值：基于图像局部的梯度方向，分配给每个关键点位置一个或多个方向，后续的所有操作都是对于关键点的方向、尺度和位置进行变换，从而提供这些特征的不变性。
   4) 特种点描述：在每个特征点周围的邻域内，在选定的尺度上测量图像的局部梯度，这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变换。
** 数据来源
1. 示例代码所用的原数据
2. 手机拍摄的图片数据
** 实验步骤
1. 计算出SIFT的关键点和描述符。
2. 对FLANN进行初始化，使用FlannBasedMatcher 寻找最近邻近似匹配，使用KTreeIndex配置索引，使用knnMatch匹配处理，并返回匹配matches，通过掩码方式计算有用的点。
3. 通过描述符的距离进行选择需要的点，通过设置coff系数来决定匹配的有效关键点数量。
4. 估计模板和场景之间的单应性，计算第二张图相对于第一张图的畸变。
5. 在场景图像中绘制检测到的模板。
6. 绘制SIFT关键点匹配。
** 结果分析与讨论
1. 示例代码数据
[[./img/sift_test_result_1.png]]

2. 手机拍摄图片数据
[[./img/sift_test_result_2.png]]

从两个数据的实验结果可看出，该实现基本上可对两张图片的相似点进行较好的提取，但对干扰点的排除有待加强
** 结论
该实现计算出SIFT的关键点和描述符后，对FLANN进行初始化，并用FLANN进行快速高效匹配，通过描述符的距离进行选择需要的点，然后对两张图片的相似点进行匹配连线。
可以考虑是否可运用到火焰图像的相似点检测上。
* 实验名称
** 实验目的（本试验的目的，一定要简单明了）
** 理论基础（说明理论的前提假设有哪些，列出具体步骤）
** 数据来源（说明数据来源，如果是火电厂历史数据，一定要写明电厂名称、时间范围、采样间隔）
** 实验步骤（列出做了哪些事，每件事情与研究内容的联系，以及之间是否存在联系）
** 结果分析与讨论（对每个试验结果进行分析，说明从试验结果得到的信息）
** 结论（列出试验取得的结论）
   
